{
  "bug_id": "107051",
  "issue_url": "https://github.com/llvm/llvm-project/issues/107051",
  "bug_type": "crash",
  "base_commit": "fcb7b390ccd5b4cfc71f13b5e16a846f3f400c10",
  "knowledge_cutoff": "2024-09-03T06:19:24Z",
  "lit_test_dir": [
    "llvm/test/Transforms/LoopVectorize"
  ],
  "hints": {
    "fix_commit": "3bd161e98d89d31696002994771b7761f1c74859",
    "components": [
      "LoopVectorize"
    ],
    "files": [
      "llvm/lib/Transforms/Vectorize/LoopVectorize.cpp"
    ],
    "bug_location_lineno": {
      "llvm/lib/Transforms/Vectorize/LoopVectorize.cpp": [
        [
          1290,
          1297
        ],
        [
          6194,
          6199
        ],
        [
          6206,
          6219
        ],
        [
          6229,
          6248
        ]
      ]
    },
    "bug_location_funcname": {
      "llvm/lib/Transforms/Vectorize/LoopVectorize.cpp": [
        "getCost",
        "setCallWideningDecision",
        "LoopVectorizationCostModel::setVectorizedCallDecision"
      ]
    }
  },
  "patch": "commit 3bd161e98d89d31696002994771b7761f1c74859\nAuthor: Florian Hahn <flo@fhahn.com>\nDate:   Tue Sep 3 21:06:31 2024 +0100\n\n    [LV] Honor forced scalars in setVectorizedCallDecision.\n    \n    Similarly to dd94537b4, setVectorizedCallDecision also did not consider\n    ForcedScalars. This lead to VPlans not reflecting the decision by the\n    legacy cost model (cost computation would use scalar cost, VPlan would\n    have VPWidenCallRecipe).\n    \n    To fix this, check if the call has been forced to scalar in\n    setVectorizedCallDecision.\n    \n    Note that this requires moving setVectorizedCallDecision after\n    collectLoopUniforms (which sets ForcedScalars). collectLoopUniforms does\n    not depend on call decisions and can safely be moved.\n    \n    Fixes https://github.com/llvm/llvm-project/issues/107051.\n\ndiff --git a/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp b/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp\nindex 17050b2b433c..0200525a718d 100644\n--- a/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp\n+++ b/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp\n@@ -1290,8 +1290,8 @@ public:\n     if (VF.isScalar() || Uniforms.contains(VF))\n       return;\n     setCostBasedWideningDecision(VF);\n-    setVectorizedCallDecision(VF);\n     collectLoopUniforms(VF);\n+    setVectorizedCallDecision(VF);\n     collectLoopScalars(VF);\n   }\n \n@@ -6194,6 +6194,7 @@ void LoopVectorizationCostModel::setVectorizedCallDecision(ElementCount VF) {\n   assert(!VF.isScalar() &&\n          \"Trying to set a vectorization decision for a scalar VF\");\n \n+  auto ForcedScalar = ForcedScalars.find(VF);\n   for (BasicBlock *BB : TheLoop->blocks()) {\n     // For each instruction in the old loop.\n     for (Instruction &I : *BB) {\n@@ -6206,14 +6207,37 @@ void LoopVectorizationCostModel::setVectorizedCallDecision(ElementCount VF) {\n       InstructionCost VectorCost = InstructionCost::getInvalid();\n       InstructionCost IntrinsicCost = InstructionCost::getInvalid();\n       TTI::TargetCostKind CostKind = TTI::TCK_RecipThroughput;\n-\n       Function *ScalarFunc = CI->getCalledFunction();\n       Type *ScalarRetTy = CI->getType();\n       SmallVector<Type *, 4> Tys, ScalarTys;\n-      bool MaskRequired = Legal->isMaskRequired(CI);\n       for (auto &ArgOp : CI->args())\n         ScalarTys.push_back(ArgOp->getType());\n \n+      // Estimate cost of scalarized vector call. The source operands are\n+      // assumed to be vectors, so we need to extract individual elements from\n+      // there, execute VF scalar calls, and then gather the result into the\n+      // vector return value.\n+      InstructionCost ScalarCallCost =\n+          TTI.getCallInstrCost(ScalarFunc, ScalarRetTy, ScalarTys, CostKind);\n+\n+      // Compute costs of unpacking argument values for the scalar calls and\n+      // packing the return values to a vector.\n+      InstructionCost ScalarizationCost =\n+          getScalarizationOverhead(CI, VF, CostKind);\n+\n+      ScalarCost = ScalarCallCost * VF.getKnownMinValue() + ScalarizationCost;\n+      // Honor ForcedScalars decision.\n+      // TODO: For calls, it might still be more profitable to widen. Use\n+      // VPlan-based cost model to compare different options.\n+      if (VF.isVector() && ForcedScalar != ForcedScalars.end() &&\n+          ForcedScalar->second.contains(CI)) {\n+        setCallWideningDecision(CI, VF, CM_Scalarize, nullptr,\n+                                Intrinsic::not_intrinsic, std::nullopt,\n+                                ScalarCost);\n+        continue;\n+      }\n+\n+      bool MaskRequired = Legal->isMaskRequired(CI);\n       // Compute corresponding vector type for return value and arguments.\n       Type *RetTy = ToVectorTy(ScalarRetTy, VF);\n       for (Type *ScalarTy : ScalarTys)\n@@ -6229,20 +6253,6 @@ void LoopVectorizationCostModel::setVectorizedCallDecision(ElementCount VF) {\n           continue;\n         }\n \n-      // Estimate cost of scalarized vector call. The source operands are\n-      // assumed to be vectors, so we need to extract individual elements from\n-      // there, execute VF scalar calls, and then gather the result into the\n-      // vector return value.\n-      InstructionCost ScalarCallCost =\n-          TTI.getCallInstrCost(ScalarFunc, ScalarRetTy, ScalarTys, CostKind);\n-\n-      // Compute costs of unpacking argument values for the scalar calls and\n-      // packing the return values to a vector.\n-      InstructionCost ScalarizationCost =\n-          getScalarizationOverhead(CI, VF, CostKind);\n-\n-      ScalarCost = ScalarCallCost * VF.getKnownMinValue() + ScalarizationCost;\n-\n       // Find the cost of vectorizing the call, if we can find a suitable\n       // vector variant of the function.\n       bool UsesMask = false;\n",
  "tests": [
    {
      "file": "llvm/test/Transforms/LoopVectorize/AArch64/call-costs.ll",
      "commands": [
        "opt -p loop-vectorize -S %s"
      ],
      "tests": [
        {
          "test_name": "call_forced_scalar",
          "test_body": "target triple = \"arm64-apple-macosx11.0.0\"\n\ndefine void @call_forced_scalar(ptr %src.1, ptr %src.2, ptr noalias %dst.1, ptr noalias %dst.2) {\nentry:\n  br label %loop\n\nloop:                                             ; preds = %loop, %entry\n  %iv = phi i64 [ 0, %entry ], [ %iv.next, %loop ]\n  %0 = load i32, ptr %src.1, align 4\n  %smax = tail call i32 @llvm.smax.i32(i32 %0, i32 0)\n  %umin = tail call i32 @llvm.umin.i32(i32 %smax, i32 1)\n  %umin.ext = zext i32 %umin to i64\n  %gep.src.2 = getelementptr i8, ptr %src.2, i64 %umin.ext\n  %1 = load i8, ptr %gep.src.2, align 1\n  %l.ext = zext i8 %1 to i32\n  %mul = mul i32 3, %l.ext\n  store i32 %mul, ptr %dst.1, align 4\n  %gep.dst.2 = getelementptr i32, ptr %dst.2, i64 %iv\n  store i32 0, ptr %gep.dst.2, align 4\n  %iv.next = add i64 %iv, 1\n  %ec = icmp eq i64 %iv.next, 0\n  br i1 %ec, label %exit, label %loop\n\nexit:                                             ; preds = %loop\n  ret void\n}\n\n; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)\ndeclare i32 @llvm.smax.i32(i32, i32) #0\n\n; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)\ndeclare i32 @llvm.umin.i32(i32, i32) #0\n\nattributes #0 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }\n"
        },
        {
          "test_name": "call_scalarized",
          "test_body": "target triple = \"arm64-apple-macosx11.0.0\"\n\ndefine void @call_scalarized(ptr noalias %src, ptr noalias %dst, double %0) {\nentry:\n  br label %loop.header\n\nloop.header:                                      ; preds = %loop.latch, %entry\n  %iv = phi i64 [ 100, %entry ], [ %iv.next, %loop.latch ]\n  %iv.next = add i64 %iv, -1\n  %gep.src = getelementptr double, ptr %src, i64 %iv.next\n  %l = load double, ptr %gep.src, align 8\n  %cmp295 = fcmp ugt double %0, 0.000000e+00\n  %cmp299 = fcmp ugt double %l, 0.000000e+00\n  %or.cond = or i1 %cmp295, %cmp299\n  br i1 %or.cond, label %loop.latch, label %then\n\nthen:                                             ; preds = %loop.header\n  %sqrt = call double @llvm.sqrt.f64(double %l)\n  %gep.dst = getelementptr double, ptr %dst, i64 %iv.next\n  store double %sqrt, ptr %gep.dst, align 8\n  br label %loop.latch\n\nloop.latch:                                       ; preds = %then, %loop.header\n  %tobool.not = icmp eq i64 %iv.next, 0\n  br i1 %tobool.not, label %exit, label %loop.header\n\nexit:                                             ; preds = %loop.latch\n  ret void\n}\n\n; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)\ndeclare double @llvm.sqrt.f64(double) #0\n\nattributes #0 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }\n"
        },
        {
          "test_name": "fshl_operand_first_order_recurrence",
          "test_body": "target triple = \"arm64-apple-macosx11.0.0\"\n\ndefine void @fshl_operand_first_order_recurrence(ptr %dst, ptr noalias %src) {\nentry:\n  br label %loop\n\nloop:                                             ; preds = %loop, %entry\n  %iv = phi i64 [ 0, %entry ], [ %iv.next, %loop ]\n  %recur = phi i64 [ 0, %entry ], [ %l, %loop ]\n  %gep.src = getelementptr inbounds i64, ptr %src, i64 %iv\n  %l = load i64, ptr %gep.src, align 8\n  %or = tail call i64 @llvm.fshl.i64(i64 1, i64 %recur, i64 1)\n  %gep.dst = getelementptr inbounds i64, ptr %dst, i64 %iv\n  store i64 %or, ptr %gep.dst, align 8\n  %iv.next = add i64 %iv, 1\n  %exitcond.not = icmp eq i64 %iv, 100\n  br i1 %exitcond.not, label %exit, label %loop\n\nexit:                                             ; preds = %loop\n  ret void\n}\n\n; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)\ndeclare i64 @llvm.fshl.i64(i64, i64, i64) #0\n\nattributes #0 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }\n"
        },
        {
          "test_name": "powi_call",
          "test_body": "target triple = \"arm64-apple-macosx11.0.0\"\n\ndefine void @powi_call(ptr %P) {\nentry:\n  br label %loop\n\nloop:                                             ; preds = %loop, %entry\n  %iv = phi i64 [ 0, %entry ], [ %iv.next, %loop ]\n  %gep = getelementptr inbounds double, ptr %P, i64 %iv\n  %l = load double, ptr %gep, align 8\n  %powi = tail call double @llvm.powi.f64.i32(double %l, i32 3)\n  store double %powi, ptr %gep, align 8\n  %iv.next = add i64 %iv, 1\n  %ec = icmp eq i64 %iv, 1\n  br i1 %ec, label %exit, label %loop\n\nexit:                                             ; preds = %loop\n  ret void\n}\n\n; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)\ndeclare double @llvm.powi.f64.i32(double, i32) #0\n\nattributes #0 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }\n"
        }
      ]
    }
  ],
  "issue": {
    "title": "[clang] Assertion failed in Vectorize",
    "body": "I compiled this code with -Os and a crash appeared in assertion failure:\r\n\r\n```c\r\n#include <stdint.h>\r\nint32_t *c;\r\nint8_t ****d;\r\nuint64_t g;\r\nint a();\r\nlong b(long, long h, long p3) {\r\n  long e;\r\n  int f = 0;\r\n  if (h) {\r\n    e = h;\r\n    f = 1;\r\n  }\r\n  if (e > p3)\r\n    f = 2;\r\n  switch (f) {\r\n  case 1:\r\n    e++;\r\n  case 2:\r\n    e--;\r\n  }\r\n  if (e < h)\r\n    e = h;\r\n  return e;\r\n}\r\n\r\nuint8_t div_func_uint8_t_u_u(uint8_t ui1, uint8_t ui2)\r\n{\r\n  return (ui1 / ui2);\r\n}\r\n\r\nuint64_t j() {\r\n  uint16_t k[8];\r\n  int i;\r\n  for (i = 0; *c + ****d + (int)g + i < 8; i++)\r\n    k[b(0, g, 0)] = 6;\r\n  *c = div_func_uint8_t_u_u(k[6], a());\r\n}\r\n```\r\n\r\nThe crash is:\r\n```\r\nclang: /root/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:7369: llvm::VectorizationFactor llvm::LoopVectorizationPlanner::computeBestVF(): Assertion `(BestFactor.Width == LegacyVF.Width || planContainsAdditionalSimplifications(getPlanFor(BestFactor.Width), CostCtx, OrigLoop)) && \" VPlan cost model and legacy cost model disagreed\"' failed.\r\n```\r\n\r\nDetails can be found here: https://godbolt.org/z/T81adKPY5\r\n\r\n",
    "author": "cardigan1008",
    "labels": [
      "vectorizers",
      "crash"
    ],
    "comments": [
      {
        "author": "patrick-rivos",
        "body": "Unreduced LLVM IR:\r\n```llvm ir\r\n; ModuleID = '/app/example.c'\r\nsource_filename = \"/app/example.c\"\r\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128\"\r\ntarget triple = \"x86_64-unknown-linux-gnu\"\r\n\r\n@c = dso_local local_unnamed_addr global ptr null, align 8\r\n@d = dso_local local_unnamed_addr global ptr null, align 8\r\n@g = dso_local local_unnamed_addr global i64 0, align 8\r\n\r\n; Function Attrs: mustprogress nofree norecurse nosync nounwind optsize willreturn memory(none) uwtable\r\ndefine dso_local i64 @b(i64 noundef %0, i64 noundef %h, i64 noundef %p3) local_unnamed_addr #0 {\r\nentry:\r\n  %tobool.not = icmp ne i64 %h, 0\r\n  %spec.select = zext i1 %tobool.not to i32\r\n  %cmp = icmp sgt i64 %h, %p3\r\n  %f.1 = select i1 %cmp, i32 2, i32 %spec.select\r\n  switch i32 %f.1, label %sw.epilog [\r\n    i32 1, label %sw.bb\r\n    i32 2, label %sw.bb3\r\n  ]\r\n\r\nsw.bb:                                            ; preds = %entry\r\n  %inc = add nsw i64 %h, 1\r\n  br label %sw.bb3\r\n\r\nsw.bb3:                                           ; preds = %entry, %sw.bb\r\n  %e.1 = phi i64 [ %h, %entry ], [ %inc, %sw.bb ]\r\n  %dec = add nsw i64 %e.1, -1\r\n  br label %sw.epilog\r\n\r\nsw.epilog:                                        ; preds = %sw.bb3, %entry\r\n  %e.2 = phi i64 [ %h, %entry ], [ %dec, %sw.bb3 ]\r\n  %spec.select14 = tail call i64 @llvm.smax.i64(i64 %e.2, i64 %h)\r\n  ret i64 %spec.select14\r\n}\r\n\r\n; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)\r\ndeclare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture) #1\r\n\r\n; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)\r\ndeclare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture) #1\r\n\r\n; Function Attrs: mustprogress nofree norecurse nosync nounwind optsize willreturn memory(none) uwtable\r\ndefine dso_local noundef zeroext i8 @div_func_uint8_t_u_u(i8 noundef zeroext %ui1, i8 noundef zeroext %ui2) local_unnamed_addr #0 {\r\nentry:\r\n  %0 = udiv i8 %ui1, %ui2\r\n  ret i8 %0\r\n}\r\n\r\n; Function Attrs: nounwind optsize uwtable\r\ndefine dso_local i64 @j() local_unnamed_addr #2 {\r\nentry:\r\n  %k = alloca [8 x i16], align 16\r\n  call void @llvm.lifetime.start.p0(i64 16, ptr nonnull %k) #5\r\n  %0 = load ptr, ptr @c, align 8, !tbaa !6\r\n  %1 = load i32, ptr %0, align 4, !tbaa !10\r\n  %2 = load ptr, ptr @d, align 8, !tbaa !6\r\n  %3 = load ptr, ptr %2, align 8, !tbaa !6\r\n  %4 = load ptr, ptr %3, align 8, !tbaa !6\r\n  %5 = load ptr, ptr %4, align 8, !tbaa !6\r\n  %6 = load i8, ptr %5, align 1, !tbaa !12\r\n  %conv = sext i8 %6 to i32\r\n  %7 = load i64, ptr @g, align 8, !tbaa !13\r\n  %conv1 = trunc i64 %7 to i32\r\n  %invariant.op = add i32 %conv, %conv1\r\n  %add3.reass12 = add i32 %1, %invariant.op\r\n  %cmp13 = icmp slt i32 %add3.reass12, 8\r\n  br i1 %cmp13, label %for.body.lr.ph, label %for.end\r\n\r\nfor.body.lr.ph:                                   ; preds = %entry\r\n  %tobool.not.i = icmp ne i64 %7, 0\r\n  %spec.select.i = zext i1 %tobool.not.i to i32\r\n  %cmp.i = icmp sgt i64 %7, 0\r\n  %f.1.i = select i1 %cmp.i, i32 2, i32 %spec.select.i\r\n  %inc.i = add nsw i64 %7, 1\r\n  br label %for.body\r\n\r\nfor.body:                                         ; preds = %for.body.lr.ph, %b.exit\r\n  %i.014 = phi i32 [ 0, %for.body.lr.ph ], [ %inc, %b.exit ]\r\n  switch i32 %f.1.i, label %b.exit [\r\n    i32 1, label %sw.bb.i\r\n    i32 2, label %sw.bb3.i\r\n  ]\r\n\r\nsw.bb.i:                                          ; preds = %for.body\r\n  br label %sw.bb3.i\r\n\r\nsw.bb3.i:                                         ; preds = %sw.bb.i, %for.body\r\n  %e.1.i = phi i64 [ %7, %for.body ], [ %inc.i, %sw.bb.i ]\r\n  %dec.i = add nsw i64 %e.1.i, -1\r\n  br label %b.exit\r\n\r\nb.exit:                                           ; preds = %for.body, %sw.bb3.i\r\n  %e.2.i = phi i64 [ %7, %for.body ], [ %dec.i, %sw.bb3.i ]\r\n  %spec.select14.i = tail call i64 @llvm.smax.i64(i64 %e.2.i, i64 %7)\r\n  %arrayidx = getelementptr inbounds [8 x i16], ptr %k, i64 0, i64 %spec.select14.i\r\n  store i16 6, ptr %arrayidx, align 2, !tbaa !15\r\n  %inc = add nuw nsw i32 %i.014, 1\r\n  %add = add i32 %1, %inc\r\n  %add3.reass = add i32 %add, %invariant.op\r\n  %cmp = icmp slt i32 %add3.reass, 8\r\n  br i1 %cmp, label %for.body, label %for.end.loopexit, !llvm.loop !17\r\n\r\nfor.end.loopexit:                                 ; preds = %b.exit\r\n  %arrayidx5.phi.trans.insert = getelementptr inbounds i8, ptr %k, i64 12\r\n  %.pre = load i16, ptr %arrayidx5.phi.trans.insert, align 4, !tbaa !15\r\n  %8 = trunc i16 %.pre to i8\r\n  br label %for.end\r\n\r\nfor.end:                                          ; preds = %for.end.loopexit, %entry\r\n  %conv6 = phi i8 [ %8, %for.end.loopexit ], [ undef, %entry ]\r\n  %call7 = tail call i32 (...) @a() #6\r\n  %conv8 = trunc i32 %call7 to i8\r\n  %9 = udiv i8 %conv6, %conv8\r\n  %conv10 = zext i8 %9 to i32\r\n  %10 = load ptr, ptr @c, align 8, !tbaa !6\r\n  store i32 %conv10, ptr %10, align 4, !tbaa !10\r\n  call void @llvm.lifetime.end.p0(i64 16, ptr nonnull %k) #5\r\n  ret i64 undef\r\n}\r\n\r\n; Function Attrs: optsize\r\ndeclare i32 @a(...) local_unnamed_addr #3\r\n\r\n; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)\r\ndeclare i64 @llvm.smax.i64(i64, i64) #4\r\n\r\nattributes #0 = { mustprogress nofree norecurse nosync nounwind optsize willreturn memory(none) uwtable \"min-legal-vector-width\"=\"0\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"tune-cpu\"=\"generic\" }\r\nattributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }\r\nattributes #2 = { nounwind optsize uwtable \"min-legal-vector-width\"=\"0\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"tune-cpu\"=\"generic\" }\r\nattributes #3 = { optsize \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"tune-cpu\"=\"generic\" }\r\nattributes #4 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }\r\nattributes #5 = { nounwind }\r\nattributes #6 = { nounwind optsize }\r\n\r\n!llvm.module.flags = !{!0, !1, !2, !3, !4}\r\n!llvm.ident = !{!5}\r\n\r\n!0 = !{i32 7, !\"Dwarf Version\", i32 4}\r\n!1 = !{i32 1, !\"wchar_size\", i32 4}\r\n!2 = !{i32 8, !\"PIC Level\", i32 2}\r\n!3 = !{i32 7, !\"PIE Level\", i32 2}\r\n!4 = !{i32 7, !\"uwtable\", i32 2}\r\n!5 = !{!\"clang version 20.0.0git (https://github.com/llvm/llvm-project.git b6597f521d8a040f2b9fee54b3f89c380de8e432)\"}\r\n!6 = !{!7, !7, i64 0}\r\n!7 = !{!\"any pointer\", !8, i64 0}\r\n!8 = !{!\"omnipotent char\", !9, i64 0}\r\n!9 = !{!\"Simple C/C++ TBAA\"}\r\n!10 = !{!11, !11, i64 0}\r\n!11 = !{!\"int\", !8, i64 0}\r\n!12 = !{!8, !8, i64 0}\r\n!13 = !{!14, !14, i64 0}\r\n!14 = !{!\"long\", !8, i64 0}\r\n!15 = !{!16, !16, i64 0}\r\n!16 = !{!\"short\", !8, i64 0}\r\n!17 = distinct !{!17, !18}\r\n!18 = !{!\"llvm.loop.mustprogress\"}\r\n```\r\n\r\nhttps://godbolt.org/z/Yo1crEjGG\r\n\r\ncc @fhahn "
      }
    ]
  }
}
