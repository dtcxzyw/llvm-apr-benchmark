{
  "bug_id": "118467",
  "issue_url": "https://github.com/llvm/llvm-project/issues/118467",
  "bug_type": "miscompilation",
  "base_commit": "73731d6873b6fb0757c3065aaf2452eaccd0eebc",
  "knowledge_cutoff": "2024-12-03T10:44:21Z",
  "lit_test_dir": [
    "llvm/test/Transforms/AggressiveInstCombine"
  ],
  "hints": {
    "fix_commit": "f68b0e36997322eeda8fd199ea80deb1b49c5410",
    "components": [
      "AggressiveInstCombine"
    ],
    "files": [
      "llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp"
    ],
    "bug_location_lineno": {
      "llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp": [
        [
          803,
          810
        ]
      ]
    },
    "bug_location_funcname": {
      "llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp": [
        "foldConsecutiveLoads"
      ]
    }
  },
  "patch": "commit f68b0e36997322eeda8fd199ea80deb1b49c5410\nAuthor: Antonio Frighetto <me@antoniofrighetto.com>\nDate:   Wed Dec 4 10:15:11 2024 +0100\n\n    [AggressiveInstCombine] Use APInt and avoid truncation when folding loads\n    \n    A miscompilation issue has been addressed with improved handling.\n    \n    Fixes: https://github.com/llvm/llvm-project/issues/118467.\n\ndiff --git a/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp b/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp\nindex b5b561797f75..45ee2d472a11 100644\n--- a/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp\n+++ b/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp\n@@ -803,8 +803,7 @@ static bool foldConsecutiveLoads(Instruction &I, const DataLayout &DL,\n     APInt Offset1(DL.getIndexTypeSizeInBits(Load1Ptr->getType()), 0);\n     Load1Ptr = Load1Ptr->stripAndAccumulateConstantOffsets(\n         DL, Offset1, /* AllowNonInbounds */ true);\n-    Load1Ptr = Builder.CreatePtrAdd(Load1Ptr,\n-                                    Builder.getInt32(Offset1.getZExtValue()));\n+    Load1Ptr = Builder.CreatePtrAdd(Load1Ptr, Builder.getInt(Offset1));\n   }\n   // Generate wider load.\n   NewLoad = Builder.CreateAlignedLoad(WiderType, Load1Ptr, LI1->getAlign(),\n",
  "tests": [
    {
      "file": "llvm/test/Transforms/AggressiveInstCombine/AArch64/or-load.ll",
      "commands": [
        "opt < %s -passes=aggressive-instcombine -S -mtriple aarch64 -data-layout=\"e-n64\"",
        "opt < %s -passes=aggressive-instcombine -S -mtriple aarch64 -data-layout=\"E-n64\""
      ],
      "tests": [
        {
          "test_name": "loadCombine_4consecutive_badinsert2",
          "test_body": "define i32 @loadCombine_4consecutive_badinsert2(ptr %p) {\n  %p1 = getelementptr i8, ptr %p, i32 1\n  %p2 = getelementptr i8, ptr %p, i32 2\n  %p3 = getelementptr i8, ptr %p, i32 3\n  %l2 = load i8, ptr %p1, align 1\n  store i8 0, ptr %p3, align 1\n  %l3 = load i8, ptr %p2, align 1\n  %l4 = load i8, ptr %p3, align 1\n  %l1 = load i8, ptr %p, align 1\n  %e1 = zext i8 %l1 to i32\n  %e2 = zext i8 %l2 to i32\n  %e3 = zext i8 %l3 to i32\n  %e4 = zext i8 %l4 to i32\n  %s2 = shl i32 %e2, 8\n  %s3 = shl i32 %e3, 16\n  %s4 = shl i32 %e4, 24\n  %o1 = or i32 %e1, %s2\n  %o2 = or i32 %o1, %s3\n  %o3 = or i32 %o2, %s4\n  ret i32 %o3\n}\n"
        },
        {
          "test_name": "loadCombine_4consecutive_badinsert6",
          "test_body": "define i32 @loadCombine_4consecutive_badinsert6(ptr %p) {\n  %p1 = getelementptr i8, ptr %p, i32 1\n  %p2 = getelementptr i8, ptr %p, i32 2\n  %p3 = getelementptr i8, ptr %p, i32 3\n  %l1 = load i8, ptr %p, align 1\n  %l2 = load i8, ptr %p1, align 1\n  store i8 0, ptr %p3, align 1\n  %l3 = load i8, ptr %p2, align 1\n  %l4 = load i8, ptr %p3, align 1\n  %e1 = zext i8 %l1 to i32\n  %e2 = zext i8 %l2 to i32\n  %e3 = zext i8 %l3 to i32\n  %e4 = zext i8 %l4 to i32\n  %s2 = shl i32 %e2, 8\n  %s3 = shl i32 %e3, 16\n  %s4 = shl i32 %e4, 24\n  %o1 = or i32 %s3, %s4\n  %o2 = or i32 %o1, %s2\n  %o3 = or i32 %o2, %e1\n  ret i32 %o3\n}\n"
        },
        {
          "test_name": "nested_gep",
          "test_body": "define void @nested_gep(ptr %p, ptr %dest) {\n  %gep1 = getelementptr inbounds i8, ptr %p, i64 72\n  %ld1 = load i32, ptr %gep1, align 4\n  %ld1_zext = zext i32 %ld1 to i64\n  %ld1_shl = shl nuw i64 %ld1_zext, 32\n  %gep2 = getelementptr inbounds i8, ptr %p, i64 64\n  %final_ptr = getelementptr inbounds i8, ptr %gep2, i64 4\n  %ld2 = load i32, ptr %final_ptr, align 4\n  %ld2_zext = zext i32 %ld2 to i64\n  %or = or i64 %ld1_shl, %ld2_zext\n  %add = add i64 %or, 0\n  %trunc = trunc i64 %add to i32\n  store i32 %trunc, ptr %dest, align 4\n  ret void\n}\n"
        }
      ]
    },
    {
      "file": "llvm/test/Transforms/AggressiveInstCombine/X86/or-load.ll",
      "commands": [
        "opt < %s -passes=aggressive-instcombine -mtriple x86_64-none-eabi -mattr=avx2 -data-layout=\"e-n64\" -S",
        "opt < %s -passes=aggressive-instcombine -mtriple x86_64-none-eabi -mattr=avx2 -data-layout=\"E-n64\" -S"
      ],
      "tests": [
        {
          "test_name": "loadCombine_4consecutive_badinsert2",
          "test_body": "define i32 @loadCombine_4consecutive_badinsert2(ptr %p) {\n  %p1 = getelementptr i8, ptr %p, i32 1\n  %p2 = getelementptr i8, ptr %p, i32 2\n  %p3 = getelementptr i8, ptr %p, i32 3\n  %l2 = load i8, ptr %p1, align 1\n  store i8 0, ptr %p3, align 1\n  %l3 = load i8, ptr %p2, align 1\n  %l4 = load i8, ptr %p3, align 1\n  %l1 = load i8, ptr %p, align 1\n  %e1 = zext i8 %l1 to i32\n  %e2 = zext i8 %l2 to i32\n  %e3 = zext i8 %l3 to i32\n  %e4 = zext i8 %l4 to i32\n  %s2 = shl i32 %e2, 8\n  %s3 = shl i32 %e3, 16\n  %s4 = shl i32 %e4, 24\n  %o1 = or i32 %e1, %s2\n  %o2 = or i32 %o1, %s3\n  %o3 = or i32 %o2, %s4\n  ret i32 %o3\n}\n"
        },
        {
          "test_name": "loadCombine_nonConstShift2",
          "test_body": "define i64 @loadCombine_nonConstShift2(ptr %arg, i8 %b) {\n  %g1 = getelementptr i8, ptr %arg, i64 1\n  %ld0 = load i8, ptr %arg, align 1\n  %ld1 = load i8, ptr %g1, align 1\n  %z0 = zext i8 %ld0 to i64\n  %z1 = zext i8 %ld1 to i64\n  %z6 = zext i8 %b to i64\n  %s0 = shl i64 %z0, %z6\n  %s1 = shl i64 %z1, 8\n  %o7 = or i64 %s1, %s0\n  ret i64 %o7\n}\n"
        },
        {
          "test_name": "nested_gep",
          "test_body": "define void @nested_gep(ptr %p, ptr %dest) {\n  %gep1 = getelementptr inbounds i8, ptr %p, i64 72\n  %ld1 = load i32, ptr %gep1, align 4\n  %ld1_zext = zext i32 %ld1 to i64\n  %ld1_shl = shl nuw i64 %ld1_zext, 32\n  %gep2 = getelementptr inbounds i8, ptr %p, i64 64\n  %final_ptr = getelementptr inbounds i8, ptr %gep2, i64 4\n  %ld2 = load i32, ptr %final_ptr, align 4\n  %ld2_zext = zext i32 %ld2 to i64\n  %or = or i64 %ld1_shl, %ld2_zext\n  %add = add i64 %or, 0\n  %trunc = trunc i64 %add to i32\n  store i32 %trunc, ptr %dest, align 4\n  ret void\n}\n"
        },
        {
          "test_name": "bitcast_gep",
          "test_body": "define void @bitcast_gep(ptr %p, ptr %dest) {\n  %gep1 = getelementptr inbounds i8, ptr %p, i64 72\n  %ld1 = load i32, ptr %gep1, align 4\n  %ld1_zext = zext i32 %ld1 to i64\n  %ld1_shl = shl nuw i64 %ld1_zext, 32\n  %gep2 = getelementptr inbounds i8, ptr %p, i64 68\n  %final_ptr = bitcast ptr %gep2 to ptr\n  %ld2 = load i32, ptr %final_ptr, align 4\n  %ld2_zext = zext i32 %ld2 to i64\n  %or = or i64 %ld1_shl, %ld2_zext\n  %add = add i64 %or, 0\n  %trunc = trunc i64 %add to i32\n  store i32 %trunc, ptr %dest, align 4\n  ret void\n}\n"
        }
      ]
    }
  ],
  "issue": {
    "title": "Invalid LLVM IR code generated on x86-64 with a very simple sample (crash the generated executable code)",
    "body": "Below is a very simple program that's loading 16 bits table value into a 32 bits variable from a 8 bits table.\nOn **x86-64** with **-O2** or **-O3** flags, this program works fine with LLVM 16.0.0 and below, but since LLVM 17.0.0, the LLVM IR and the generated assembly code are using a wrong calculated offset on the table (doesn't occurs on LLVM armv8 whatever the version).\nAs you can see below, the offset in the table which is supposed to be **2149675576** (**0x80217238**) has its 32 upper bits inverted for **-2145291720** (**0xFFFFFFFF80217238**).\n\n```c\n\n#include <stdint.h>\n\n// Load 16 bits into 32 bits value from data offset 0x80217238\n\nuint32_t Test(const uint8_t* data)\n{        \n    uint32_t a, b, c;    \n\tb = 0xFFFF8022 << 16;\n    b += 0xFFFFE808;    \n    a = data[b + 0xFFFF8A31];\n    c = data[b + 0xFFFF8A30];\n    c &= ~0x0000FF00;\n    c |= ((a << 8) | (a >> 24)) & 0x0000FF00;\n\treturn c;\n}\n\n```\n\nLLVM IR with LLVM 16.0.0 (from Compiler Explorer)\n```ll\ndefine dso_local noundef i32 @Test(unsigned char const*)(ptr nocapture noundef readonly %data) local_unnamed_addr {\nentry:\n  %arrayidx4 = getelementptr inbounds i8, ptr %data, i64 2149675576\n  %0 = load i16, ptr %arrayidx4, align 1\n  %1 = zext i16 %0 to i32\n  ret i32 %1\n}\n\ndeclare void @llvm.dbg.value(metadata, metadata, metadata) #1\n```\nLLVM IR with LLVM 19.1.0 and trunk (from Compiler Explorer)\n```ll\ndefine dso_local noundef range(i32 0, 65536) i32 @Test(unsigned char const*)(ptr nocapture noundef readonly %data) local_unnamed_addr {\nentry:\n  %0 = getelementptr i8, ptr %data, i64 -2145291720\n  %1 = load i16, ptr %0, align 1\n  %2 = zext i16 %1 to i32\n  ret i32 %2\n}\n```\n\n\n\n\n\n",
    "author": "dje64240",
    "labels": [
      "miscompilation",
      "llvm:transforms"
    ],
    "comments": [
      {
        "author": "topperc",
        "body": "opt-bisect suggests AggressiveInstCominer. There were two separate loads that got merged. The resulting GEP had an index of `i32 -2145291720` with trunk and `i64 2149675576` with clang 16. Those would be the same number if GEP zero extended indices instead of sign extending."
      },
      {
        "author": "antoniofrighetto",
        "body": "Alive2: https://alive2.llvm.org/ce/z/G5CgkD."
      },
      {
        "author": "AZero13",
        "body": "> opt-bisect suggests AggressiveInstCominer. There were two separate loads that got merged. The resulting GEP had an index of `i32 -2145291720` with trunk and `i64 2149675576` with clang 16. Those would be the same number if GEP zero extended indices instead of sign extending.\n\nSee my PR for 19.x "
      }
    ]
  }
}